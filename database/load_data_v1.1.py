#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìˆ˜í•™ê³¼ êµìœ¡ê³¼ì • ë°ì´í„° PostgreSQL ë¡œë”© ìŠ¤í¬ë¦½íŠ¸
==============================================

ì„¤ëª…: CSV íŒŒì¼ë“¤ì„ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë¡œë”©í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
ì‘ì„±ì¼: 2024-12-19
ìˆ˜ì •ì¼: 2025-01-21
ë²„ì „: 1.1.0

í•„ìš” íŒ¨í‚¤ì§€:
- psycopg2-binary
- pandas
- python-dotenv

ì„¤ì¹˜ ë°©ë²•:
pip install psycopg2-binary pandas python-dotenv
"""

import os
import sys
import csv
import logging
import pandas as pd
import psycopg2
from psycopg2.extras import execute_values
from dotenv import load_dotenv
from typing import List, Dict, Any, Optional
from pathlib import Path
import json
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_loading.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class MathCurriculumLoader:
    """ìˆ˜í•™ê³¼ êµìœ¡ê³¼ì • ë°ì´í„° ë¡œë” í´ë˜ìŠ¤"""
    
    def __init__(self, config_file: str = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            config_file: ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì˜µì…˜)
        """
        self.base_path = Path(__file__).parent.parent
        self.data_path = self.base_path / "data"
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´
        self.db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': os.getenv('DB_PORT', '5432'),
            'database': os.getenv('DB_NAME', 'mathematics_curriculum'),
            'user': os.getenv('DB_USER', 'postgres'),
            'password': os.getenv('DB_PASSWORD', 'password')
        }
        
        self.schema = os.getenv('DB_SCHEMA', 'curriculum')
        self.connection = None
        self.stats = {
            'total_records': 0,
            'successful_inserts': 0,
            'failed_inserts': 0,
            'tables_loaded': [],
            'start_time': None,
            'end_time': None
        }
        
        logger.info(f"ë°ì´í„° ê²½ë¡œ: {self.data_path}")
        logger.info(f"ë°ì´í„°ë² ì´ìŠ¤: {self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}")

    def connect_database(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        try:
            self.connection = psycopg2.connect(**self.db_config)
            self.connection.autocommit = False
            
            # ìŠ¤í‚¤ë§ˆ ì„¤ì •
            with self.connection.cursor() as cursor:
                cursor.execute(f"SET search_path TO {self.schema}, public;")
            
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
            return True
            
        except psycopg2.Error as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def disconnect_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•´ì œ"""
        if self.connection:
            self.connection.close()
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•´ì œ")

    def load_csv_file(self, file_path: Path, encoding: str = 'utf-8') -> Optional[pd.DataFrame]:
        """CSV íŒŒì¼ ë¡œë“œ"""
        try:
            df = pd.read_csv(file_path, encoding=encoding)
            logger.info(f"CSV íŒŒì¼ ë¡œë“œ ì„±ê³µ: {file_path.name} ({len(df)} í–‰)")
            return df
            
        except Exception as e:
            logger.error(f"CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file_path.name} - {e}")
            return None

    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë°ì´í„° ì •ë¦¬"""
        # NaN ê°’ì„ Noneìœ¼ë¡œ ë³€ê²½ (PostgreSQL NULLë¡œ ë³€í™˜ë¨)
        df = df.where(pd.notnull(df), None)
        
        # ë¬¸ìì—´ ì»¬ëŸ¼ì˜ ì•ë’¤ ê³µë°± ì œê±°
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].apply(lambda x: x.strip() if isinstance(x, str) else x)
        
        return df

    def insert_data(self, table_name: str, df: pd.DataFrame, 
                   conflict_column: str = None) -> bool:
        """ë°ì´í„° ì‚½ì…"""
        try:
            with self.connection.cursor() as cursor:
                # ì»¬ëŸ¼ëª… ê°€ì ¸ì˜¤ê¸°
                columns = df.columns.tolist()
                
                # ê°’ ì¤€ë¹„
                values = [tuple(row) for row in df.values]
                
                # SQL ì¿¼ë¦¬ ìƒì„±
                columns_str = ', '.join(columns)
                placeholders = ', '.join(['%s'] * len(columns))
                
                if conflict_column:
                    # UPSERT (ON CONFLICT DO UPDATE)
                    update_columns = [f"{col} = EXCLUDED.{col}" 
                                    for col in columns if col != conflict_column]
                    update_str = ', '.join(update_columns)
                    
                    sql = f"""
                    INSERT INTO {table_name} ({columns_str}) 
                    VALUES %s 
                    ON CONFLICT ({conflict_column}) 
                    DO UPDATE SET {update_str}
                    """
                else:
                    # ì¼ë°˜ INSERT
                    sql = f"INSERT INTO {table_name} ({columns_str}) VALUES %s"
                
                # ë°ì´í„° ì‚½ì…
                execute_values(cursor, sql, values, template=None, page_size=1000)
                
                affected_rows = cursor.rowcount
                self.stats['successful_inserts'] += affected_rows
                
                logger.info(f"{table_name} í…Œì´ë¸”ì— {affected_rows}ê°œ ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ")
                return True
                
        except psycopg2.Error as e:
            logger.error(f"{table_name} ë°ì´í„° ì‚½ì… ì‹¤íŒ¨: {e}")
            self.stats['failed_inserts'] += len(df)
            return False

    def load_reference_data(self) -> bool:
        """ê¸°ì¤€ ë°ì´í„° ë¡œë”©"""
        logger.info("=== ê¸°ì¤€ ë°ì´í„° ë¡œë”© ì‹œì‘ ===")
        
        reference_files = [
            ('school_levels.csv', 'school_levels', 'level_id'),
            ('domains.csv', 'domains', 'domain_id'),
            ('categories.csv', 'categories', 'category_id')
        ]
        
        for file_name, table_name, conflict_col in reference_files:
            file_path = self.data_path / "reference" / file_name
            
            if not file_path.exists():
                logger.warning(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
                continue
            
            df = self.load_csv_file(file_path)
            if df is not None:
                df = self.clean_data(df)
                success = self.insert_data(table_name, df, conflict_col)
                if success:
                    self.stats['tables_loaded'].append(table_name)
                    self.stats['total_records'] += len(df)
        
        return True

    def load_content_system_data(self) -> bool:
        """ë‚´ìš© ì²´ê³„ ë°ì´í„° ë¡œë”©"""
        logger.info("=== ë‚´ìš© ì²´ê³„ ë°ì´í„° ë¡œë”© ì‹œì‘ ===")
        
        # í•µì‹¬ ì•„ì´ë””ì–´ ë¡œë”©
        file_path = self.data_path / "content_system" / "core_ideas.csv"
        if file_path.exists():
            df = self.load_csv_file(file_path)
            if df is not None:
                df = self.clean_data(df)
                success = self.insert_data('core_ideas', df, 'idea_id')
                if success:
                    self.stats['tables_loaded'].append('core_ideas')
                    self.stats['total_records'] += len(df)
        
        # ë‚´ìš© ìš”ì†Œ ë¡œë”©
        content_element_files = [
            'content_elements_elementary_1-2.csv',
            'content_elements_elementary_3-4.csv',
            'content_elements_elementary_5-6.csv',
            'content_elements_middle_1-3.csv'
        ]
        
        all_elements = []
        for file_name in content_element_files:
            file_path = self.data_path / "content_system" / file_name
            if file_path.exists():
                df = self.load_csv_file(file_path)
                if df is not None:
                    all_elements.append(df)
        
        if all_elements:
            combined_df = pd.concat(all_elements, ignore_index=True)
            combined_df = self.clean_data(combined_df)
            success = self.insert_data('content_elements', combined_df, 'element_id')
            if success:
                self.stats['tables_loaded'].append('content_elements')
                self.stats['total_records'] += len(combined_df)
        
        # í•™ìŠµ ìš”ì†Œ ë¡œë”©
        learning_element_files = [
            'learning_elements_elementary_1-2.csv',
            'learning_elements_elementary_3-4.csv',
            'learning_elements_elementary_5-6.csv',
            'learning_elements_middle_1-3.csv'
        ]
        
        all_learning = []
        for file_name in learning_element_files:
            file_path = self.data_path / "content_system" / file_name
            if file_path.exists():
                df = self.load_csv_file(file_path)
                if df is not None:
                    all_learning.append(df)
        
        if all_learning:
            combined_df = pd.concat(all_learning, ignore_index=True)
            combined_df = self.clean_data(combined_df)
            success = self.insert_data('learning_elements', combined_df, 'learning_id')
            if success:
                self.stats['tables_loaded'].append('learning_elements')
                self.stats['total_records'] += len(combined_df)
        
        return True

    def load_achievement_standards_data(self) -> bool:
        """ì„±ì·¨ê¸°ì¤€ ë°ì´í„° ë¡œë”©"""
        logger.info("=== ì„±ì·¨ê¸°ì¤€ ë°ì´í„° ë¡œë”© ì‹œì‘ ===")
        
        # ì„±ì·¨ê¸°ì¤€ ë¡œë”©
        achievement_files = [
            'achievement_standards_elementary_1-2.csv',
            'achievement_standards_elementary_3-4.csv',
            'achievement_standards_elementary_5-6.csv',
            'achievement_standards_middle_1-3.csv'
        ]
        
        all_standards = []
        for file_name in achievement_files:
            file_path = self.data_path / "achievement_standards" / file_name
            if file_path.exists():
                df = self.load_csv_file(file_path)
                if df is not None:
                    all_standards.append(df)
        
        if all_standards:
            combined_df = pd.concat(all_standards, ignore_index=True)
            combined_df = self.clean_data(combined_df)
            success = self.insert_data('achievement_standards', combined_df, 'standard_id')
            if success:
                self.stats['tables_loaded'].append('achievement_standards')
                self.stats['total_records'] += len(combined_df)
        
        # ì„±ì·¨ê¸°ì¤€ í•´ì„¤ ë¡œë”©
        explanation_files = [
            'standard_explanations_elementary_1-2.csv',
            'standard_explanations_elementary_3-4.csv',
            'standard_explanations_elementary_5-6.csv',
            'standard_explanations_middle_1-3.csv'
        ]
        
        all_explanations = []
        for file_name in explanation_files:
            file_path = self.data_path / "achievement_standards" / file_name
            if file_path.exists():
                df = self.load_csv_file(file_path)
                if df is not None:
                    # standard_idê°€ 0ì¸ ê²½ìš° NULLë¡œ ë³€ê²½ (ìš©ì–´ì™€ ê¸°í˜¸)
                    df['standard_id'] = df['standard_id'].apply(lambda x: None if x == 0 else x)
                    all_explanations.append(df)
        
        if all_explanations:
            combined_df = pd.concat(all_explanations, ignore_index=True)
            combined_df = self.clean_data(combined_df)
            success = self.insert_data('standard_explanations', combined_df, 'explanation_id')
            if success:
                self.stats['tables_loaded'].append('standard_explanations')
                self.stats['total_records'] += len(combined_df)
        
        return True

    def load_terms_symbols_data(self) -> bool:
        """ìš©ì–´ ë° ê¸°í˜¸ ë°ì´í„° ë¡œë”©"""
        logger.info("=== ìš©ì–´ ë° ê¸°í˜¸ ë°ì´í„° ë¡œë”© ì‹œì‘ ===")
        
        terms_files = [
            'terms_symbols_elementary_1-2.csv',
            'terms_symbols_elementary_3-4.csv',
            'terms_symbols_elementary_5-6.csv',
            'terms_symbols_middle_1-3.csv'
        ]
        
        all_terms = []
        for file_name in terms_files:
            file_path = self.data_path / "terms_symbols" / file_name
            if file_path.exists():
                df = self.load_csv_file(file_path)
                if df is not None:
                    # LaTeX í‘œí˜„ ê°ì§€ ë° ì²˜ë¦¬
                    if 'term_name' in df.columns:
                        # ìˆ˜í•™ ê¸°í˜¸ê°€ í¬í•¨ëœ ê²½ìš° latex_expression ì»¬ëŸ¼ ì¶”ê°€
                        df['latex_expression'] = df['term_name'].apply(
                            lambda x: self.extract_latex(x) if isinstance(x, str) else None
                        )
                    
                    all_terms.append(df)
        
        if all_terms:
            combined_df = pd.concat(all_terms, ignore_index=True)
            combined_df = self.clean_data(combined_df)
            success = self.insert_data('terms_symbols', combined_df, 'term_id')
            if success:
                self.stats['tables_loaded'].append('terms_symbols')
                self.stats['total_records'] += len(combined_df)
        
        return True
    
    def extract_latex(self, text: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ LaTeX í‘œí˜„ ì¶”ì¶œ"""
        # íŠ¹ìˆ˜ ìˆ˜í•™ ê¸°í˜¸ê°€ í¬í•¨ëœ ê²½ìš°
        math_symbols = ['âˆš', 'âˆ', 'âˆ‘', 'âˆ', 'âˆ«', 'â‰¤', 'â‰¥', 'â‰ ', 'Â±', 'âˆˆ', 'âˆ‰', 'âŠ‚', 'âŠƒ', 'âˆª', 'âˆ©']
        
        for symbol in math_symbols:
            if symbol in text:
                return text  # LaTeX ë³€í™˜ì´ í•„ìš”í•œ ê²½ìš°
        
        # $ ê¸°í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ìˆ˜ì‹
        if '$' in text:
            return text
        
        return None

    def validate_data(self) -> bool:
        """ë°ì´í„° ê²€ì¦"""
        logger.info("=== ë°ì´í„° ê²€ì¦ ì‹œì‘ ===")
        
        try:
            with self.connection.cursor() as cursor:
                # ê¸°ë³¸ ì¹´ìš´íŠ¸ ê²€ì¦
                validation_queries = [
                    ("SELECT COUNT(*) FROM school_levels", "í•™êµê¸‰"),
                    ("SELECT COUNT(*) FROM domains", "ì˜ì—­"),
                    ("SELECT COUNT(*) FROM categories", "ë²”ì£¼"),
                    ("SELECT COUNT(*) FROM core_ideas", "í•µì‹¬ì•„ì´ë””ì–´"),
                    ("SELECT COUNT(*) FROM content_elements", "ë‚´ìš©ìš”ì†Œ"),
                    ("SELECT COUNT(*) FROM learning_elements", "í•™ìŠµìš”ì†Œ"),
                    ("SELECT COUNT(*) FROM achievement_standards", "ì„±ì·¨ê¸°ì¤€"),
                    ("SELECT COUNT(*) FROM standard_explanations", "ì„±ì·¨ê¸°ì¤€í•´ì„¤"),
                    ("SELECT COUNT(*) FROM terms_symbols", "ìš©ì–´ê¸°í˜¸")
                ]
                
                logger.info("ë°ì´í„° ì¹´ìš´íŠ¸ ê²€ì¦:")
                for query, name in validation_queries:
                    cursor.execute(query)
                    count = cursor.fetchone()[0]
                    logger.info(f"  {name}: {count:,}ê°œ")
                
                # ì°¸ì¡° ë¬´ê²°ì„± ê²€ì¦
                integrity_queries = [
                    ("""
                    SELECT COUNT(*) FROM achievement_standards ast 
                    LEFT JOIN school_levels sl ON ast.level_id = sl.level_id 
                    WHERE sl.level_id IS NULL
                    """, "ì„±ì·¨ê¸°ì¤€ì˜ í•™ë…„ ì°¸ì¡° ì˜¤ë¥˜"),
                    
                    ("""
                    SELECT COUNT(*) FROM achievement_standards ast 
                    LEFT JOIN domains d ON ast.domain_id = d.domain_id 
                    WHERE d.domain_id IS NULL
                    """, "ì„±ì·¨ê¸°ì¤€ì˜ ì˜ì—­ ì°¸ì¡° ì˜¤ë¥˜"),
                    
                    ("""
                    SELECT COUNT(*) FROM content_elements ce 
                    LEFT JOIN school_levels sl ON ce.level_id = sl.level_id 
                    WHERE sl.level_id IS NULL
                    """, "ë‚´ìš©ìš”ì†Œì˜ í•™ë…„ ì°¸ì¡° ì˜¤ë¥˜"),
                    
                    ("""
                    SELECT COUNT(*) FROM terms_symbols ts 
                    LEFT JOIN school_levels sl ON ts.level_id = sl.level_id 
                    WHERE sl.level_id IS NULL
                    """, "ìš©ì–´ê¸°í˜¸ì˜ í•™ë…„ ì°¸ì¡° ì˜¤ë¥˜")
                ]
                
                logger.info("ì°¸ì¡° ë¬´ê²°ì„± ê²€ì¦:")
                all_valid = True
                for query, name in integrity_queries:
                    cursor.execute(query)
                    count = cursor.fetchone()[0]
                    if count > 0:
                        logger.warning(f"  {name}: {count}ê°œ ë°œê²¬")
                        all_valid = False
                    else:
                        logger.info(f"  {name}: ì •ìƒ")
                
                # ì„±ì·¨ê¸°ì¤€ ì½”ë“œ í˜•ì‹ ê²€ì¦
                cursor.execute("""
                    SELECT COUNT(*) FROM achievement_standards 
                    WHERE NOT (standard_code ~ '^[0-9]{1,2}ìˆ˜[0-9]{2}-[0-9]{2}$')
                """)
                invalid_codes = cursor.fetchone()[0]
                if invalid_codes > 0:
                    logger.warning(f"  ì˜ëª»ëœ ì„±ì·¨ê¸°ì¤€ ì½”ë“œ í˜•ì‹: {invalid_codes}ê°œ")
                    all_valid = False
                else:
                    logger.info("  ì„±ì·¨ê¸°ì¤€ ì½”ë“œ í˜•ì‹: ì •ìƒ")
                
                return all_valid
                
        except Exception as e:
            logger.error(f"ë°ì´í„° ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def generate_report(self) -> Dict[str, Any]:
        """ë¡œë”© ë³´ê³ ì„œ ìƒì„±"""
        duration = None
        if self.stats['start_time'] and self.stats['end_time']:
            duration = (self.stats['end_time'] - self.stats['start_time']).total_seconds()
        
        report = {
            'loading_summary': {
                'total_records': self.stats['total_records'],
                'successful_inserts': self.stats['successful_inserts'],
                'failed_inserts': self.stats['failed_inserts'],
                'tables_loaded': self.stats['tables_loaded'],
                'duration_seconds': duration
            },
            'database_info': {
                'host': self.db_config['host'],
                'database': self.db_config['database'],
                'schema': self.schema
            },
            'timestamp': datetime.now().isoformat()
        }
        
        return report

    def save_report(self, report: Dict[str, Any]):
        """ë³´ê³ ì„œ ì €ì¥"""
        report_file = self.base_path / "database" / "loading_report.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ë¡œë”© ë³´ê³ ì„œ ì €ì¥: {report_file}")

    def load_all_data(self) -> bool:
        """ì „ì²´ ë°ì´í„° ë¡œë”© ì‹¤í–‰"""
        logger.info("ğŸš€ ìˆ˜í•™ê³¼ êµìœ¡ê³¼ì • ë°ì´í„° ë¡œë”© ì‹œì‘")
        self.stats['start_time'] = datetime.now()
        
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            if not self.connect_database():
                return False
            
            # íŠ¸ëœì­ì…˜ ì‹œì‘
            with self.connection.cursor() as cursor:
                cursor.execute("BEGIN")
            
            # ìˆœì„œëŒ€ë¡œ ë°ì´í„° ë¡œë”© (ì™¸ë˜í‚¤ ì˜ì¡´ì„± ê³ ë ¤)
            success = (
                self.load_reference_data() and
                self.load_content_system_data() and
                self.load_achievement_standards_data() and
                self.load_terms_symbols_data()
            )
            
            if success:
                # ë°ì´í„° ê²€ì¦
                if self.validate_data():
                    # ì»¤ë°‹
                    self.connection.commit()
                    logger.info("âœ… ëª¨ë“  ë°ì´í„° ë¡œë”© ì™„ë£Œ ë° ì»¤ë°‹")
                else:
                    # ë¡¤ë°±
                    self.connection.rollback()
                    logger.warning("âš ï¸ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨ë¡œ ë¡¤ë°±")
                    success = False
            else:
                # ë¡¤ë°±
                self.connection.rollback()
                logger.error("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ë¡œ ë¡¤ë°±")
            
            self.stats['end_time'] = datetime.now()
            
            # ë³´ê³ ì„œ ìƒì„± ë° ì €ì¥
            report = self.generate_report()
            self.save_report(report)
            
            # ìµœì¢… í†µê³„ ì¶œë ¥
            logger.info("ğŸ“Š ë¡œë”© í†µê³„:")
            logger.info(f"  ì´ ë ˆì½”ë“œ: {self.stats['total_records']:,}ê°œ")
            logger.info(f"  ì„±ê³µí•œ ì‚½ì…: {self.stats['successful_inserts']:,}ê°œ")
            logger.info(f"  ì‹¤íŒ¨í•œ ì‚½ì…: {self.stats['failed_inserts']:,}ê°œ")
            logger.info(f"  ë¡œë”©ëœ í…Œì´ë¸”: {', '.join(self.stats['tables_loaded'])}")
            
            if self.stats['start_time'] and self.stats['end_time']:
                duration = self.stats['end_time'] - self.stats['start_time']
                logger.info(f"  ì†Œìš” ì‹œê°„: {duration.total_seconds():.2f}ì´ˆ")
            
            return success
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            if self.connection:
                self.connection.rollback()
            return False
            
        finally:
            self.disconnect_database()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ìˆ˜í•™ê³¼ êµìœ¡ê³¼ì • ë°ì´í„° PostgreSQL ë¡œë”')
    parser.add_argument('--config', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--dry-run', action='store_true', help='ì‹¤ì œ ì‚½ì… ì—†ì´ ê²€ì¦ë§Œ ìˆ˜í–‰')
    
    args = parser.parse_args()
    
    # í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ í™•ì¸
    env_file = Path('.env')
    if not env_file.exists():
        logger.warning(".env íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        logger.info("í™˜ê²½ ë³€ìˆ˜ ì˜ˆì‹œ:")
        logger.info("DB_HOST=localhost")
        logger.info("DB_PORT=5432")
        logger.info("DB_NAME=mathematics_curriculum")
        logger.info("DB_USER=postgres")
        logger.info("DB_PASSWORD=your_password")
        logger.info("DB_SCHEMA=curriculum")
    
    # ë¡œë” ì‹¤í–‰
    loader = MathCurriculumLoader(args.config)
    success = loader.load_all_data()
    
    if success:
        logger.info("ğŸ‰ ë°ì´í„° ë¡œë”©ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        sys.exit(0)
    else:
        logger.error("ğŸ’¥ ë°ì´í„° ë¡œë”©ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)


if __name__ == "__main__":
    main()
