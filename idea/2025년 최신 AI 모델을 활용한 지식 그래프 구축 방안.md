# 🧠 2025년 최신 AI 모델을 활용한 지식 그래프 구축 방안

## 📋 현황 분석

### 사전 구축 대상 리스트 검토
- ✅ **데이터 준비**: 181개 성취기준, 843개 성취수준 완료
- 🎯 **지식 그래프 구성 요소**: AI 모델 활용 구축 대상
- 📊 **벡터 데이터베이스**: 1,024개 문서 임베딩 준비
- 📚 **수학 용어 사전**: 학년별 핵심 용어 체계
- 🎨 **프롬프트 템플릿**: 각 AI 모델별 최적화 필요
- ✔️ **검증 데이터셋**: 품질 보증용 샘플 문항

### 2025년 활용 가능 AI 모델
| 모델 | 가격 (입력/출력) | 강점 | 활용 영역 |
|------|------------------|------|-----------|
| **Gemini 2.5 Pro** | $1.25/$10 | 1M 토큰, 멀티모달 | 전체 문서 분석 |
| **GPT-5** | $1.25/$10 | 수학 성능(94.6%), 비용효율 | 대량 관계 추출 |
| **Claude Sonnet 4** | $3/$15 | 하이브리드 추론, 1M 토큰 | 복잡한 관계 정의 |
| **Claude Opus 4.1** | $15/$75 | 최고 성능, 장시간 작업 | 고도 추론, 검증 |

---

## 🎯 AI 모델별 역할 분담 전략

### 1. **Gemini 2.5 Pro** - 거시적 구조 설계자
```
활용 목적: 전체 교육과정 문서 통합 분석
강점 활용: 1M 토큰 컨텍스트, 네이티브 멀티모달

담당 업무:
├── 전체 노드 체계 설계
├── 거시적 관계 구조 파악  
├── 커뮤니티 클러스터 초안 작성
└── 교육과정 전반의 일관성 검토

예상 비용: $15-25 (1회 대용량 처리)
```

### 2. **GPT-5** - 효율적 대량 처리자
```
활용 목적: 성취기준 간 관계 대량 추출
강점 활용: 뛰어난 수학 성능, 비용 효율성

담당 업무:
├── 181개 성취기준 간 유사도 계산
├── 기본적인 선후 관계 추출
├── 동의어/유사어 매핑
└── 초기 가중치 계산

최적화: 배치 API 50% 할인 + 프롬프트 캐싱 75% 할인
예상 비용: $30-50
```

### 3. **Claude Sonnet 4** - 세밀한 관계 분석가
```
활용 목적: 복잡한 교육적 관계 정의
강점 활용: 하이브리드 추론, 교육적 해석

담당 업무:
├── 엣지 타입 세분화 (12종)
├── 교육적 맥락 고려한 가중치 조정
├── 학습 순서 관계 정밀 분석
└── 영역 간 융합 관계 정의

최적화: 프롬프트 캐싱 90% 할인
예상 비용: $20-40
```

### 4. **Claude Opus 4.1** - 최종 검증 전문가
```
활용 목적: 전체 그래프 품질 검증
강점 활용: 최고 성능, 장시간 지속 작업

담당 업무:
├── 순환 참조 탐지 및 제거
├── 선수학습 체인 논리 검증
├── 커뮤니티 클러스터 교육적 타당성 검토
└── 최종 일관성 검사

예상 비용: $50-100
```

---

## 🔄 단계별 구축 프로세스

### **Phase 1: 기반 구조 설계 (1주)**

#### Step 1.1: 전체 문서 통합 분석 (Gemini 2.5 Pro)
```python
# 프롬프트 예시
prompt = f"""
전체 한국 수학 교육과정 문서를 분석하여 지식 그래프 구조를 설계하세요.

입력 데이터:
- 181개 성취기준: {achievement_standards}
- 843개 성취수준: {achievement_levels}
- 영역별 핵심 아이디어: {core_ideas}

출력 요구사항:
1. 노드 타입 및 속성 정의
2. 주요 관계 카테고리 식별
3. 계층 구조 설계
4. 커뮤니티 클러스터 초안 (3레벨)

분석 기준:
- 교육과정의 계열성과 연계성
- 학습자 인지 발달 수준
- 수학적 개념의 논리적 구조
"""

# 처리 방식
response = gemini_pro.generate_content(
    contents=prompt,
    generation_config={
        "temperature": 0.2,
        "max_output_tokens": 4000
    }
)
```

#### Step 1.2: 노드 속성 자동 추출
```json
{
  "node_types": {
    "achievement_standard": {
      "properties": ["code", "content", "difficulty", "cognitive_level", "prerequisites"],
      "attributes": {
        "difficulty": "1-5 scale",
        "cognitive_level": "remember/understand/apply/analyze/evaluate/create",
        "estimated_hours": "학습 소요 시간"
      }
    },
    "achievement_level": {
      "properties": ["level", "description", "assessment_criteria"],
      "attributes": {
        "complexity": "텍스트 복잡도",
        "skill_type": "절차적/개념적/문제해결"
      }
    }
  }
}
```

### **Phase 2: 관계 추출 및 분류 (2주)**

#### Step 2.1: 대량 유사도 계산 (GPT-5 배치 처리)
```python
# 배치 작업 설정
batch_requests = []
for i, standard_a in enumerate(achievement_standards):
    for j, standard_b in enumerate(achievement_standards[i+1:]):
        request = {
            "custom_id": f"similarity_{i}_{j}",
            "method": "POST",
            "url": "/v1/chat/completions",
            "body": {
                "model": "gpt-5",
                "messages": [
                    {
                        "role": "system",
                        "content": "성취기준 간 관계를 분석하여 유사도와 관계 유형을 판정하세요."
                    },
                    {
                        "role": "user", 
                        "content": f"성취기준 A: {standard_a}\n성취기준 B: {standard_b}"
                    }
                ],
                "temperature": 0.1
            }
        }
        batch_requests.append(request)

# 배치 실행 (50% 할인 적용)
batch_job = client.batches.create(
    input_file_id=upload_batch_file(batch_requests),
    endpoint="/v1/chat/completions",
    completion_window="24h"
)
```

#### Step 2.2: 선수학습 관계 추출
```python
# 프롬프트 최적화 (프롬프트 캐싱 활용)
prerequisite_prompt = """
<cached_context>
한국 수학 교육과정 체계:
- 학년군별 인지 발달 특성
- 수학적 개념의 위계성 원리
- 나선형 교육과정 구조
</cached_context>

다음 성취기준들 간의 선수학습 관계를 분석하세요:
{standard_pair}

출력 형식:
{
  "relationship": "prerequisite/corequisite/follows/independent",
  "strength": 0.0-1.0,
  "reasoning": "판단 근거",
  "learning_path": ["step1", "step2", "step3"]
}
"""
```

### **Phase 3: 고도화 및 세분화 (1주)**

#### Step 3.1: 엣지 타입 세분화 (Claude Sonnet 4)
```python
edge_refinement_prompt = """
기본 관계 분류 결과를 바탕으로 교육적 의미를 고려한 세분화를 수행하세요.

기본 관계:
{basic_relationships}

세분화 기준:
1. 교육과정 명시성 (명시적/암시적)
2. 학습 필수성 (필수/권장/참고)
3. 관계 강도 (강함/중간/약함)
4. 시간적 순서 (선행/동시/후행)

출력: 12가지 엣지 타입별 분류 및 가중치
"""

# 하이브리드 추론 활성화
response = claude_sonnet.messages.create(
    model="claude-sonnet-4-20250514",
    messages=[{"role": "user", "content": edge_refinement_prompt}],
    thinking_budget=3000,  # 확장된 사고 모드
    max_tokens=4000
)
```

#### Step 3.2: 가중치 미세 조정
```json
{
  "edge_weights": {
    "prerequisite_explicit": 1.0,
    "prerequisite_implicit": 0.8,
    "corequisite_strong": 0.9,
    "corequisite_weak": 0.6,
    "similarity_concept": 0.7,
    "similarity_method": 0.5,
    "domain_bridge": 0.4,
    "grade_progression": 0.8
  },
  "adjustment_factors": {
    "same_grade": 1.2,
    "adjacent_grade": 1.0,
    "distant_grade": 0.7,
    "same_domain": 1.1,
    "cross_domain": 0.9
  }
}
```

### **Phase 4: 검증 및 최적화 (1주)**

#### Step 4.1: 전체 그래프 일관성 검증 (Claude Opus 4.1)
```python
validation_prompt = """
구축된 지식 그래프의 전체적 일관성을 검증하세요.

그래프 구조:
- 노드 수: {node_count}
- 엣지 수: {edge_count}  
- 연결 성분: {components}

검증 항목:
1. 순환 참조 탐지
2. 고아 노드 확인
3. 선수학습 체인 논리성
4. 커뮤니티 클러스터 품질
5. 교육과정 문서와의 일치성

각 항목별 문제점과 수정 제안을 제시하세요.
"""

# 장시간 작업 모드 활성화
response = claude_opus.messages.create(
    model="claude-opus-4-1-20250514", 
    messages=[{"role": "user", "content": validation_prompt}],
    thinking_budget=5000,  # 최대 사고 토큰
    max_tokens=8000
)
```

#### Step 4.2: 커뮤니티 탐지 결과 검증
```python
# NetworkX + Louvain 알고리즘 결과와 AI 분석 비교
community_analysis = """
자동 탐지된 커뮤니티 클러스터의 교육적 타당성을 평가하세요.

Level 0 클러스터 (8개):
{level_0_communities}

Level 1 클러스터 (24개):  
{level_1_communities}

Level 2 클러스터 (48개):
{level_2_communities}

평가 기준:
- 교육과정 영역과의 일치성
- 학년군별 분포의 적절성
- 인지적 부하 균형성
- 교수학습 연계성
"""
```

---

## 💰 비용 최적화 전략

### 1. **캐싱 활용 극대화**
```
Claude 모델 (90% 할인):
- 기본 교육과정 컨텍스트 캐싱
- 분석 기준 문서 캐싱
- 예시 분류 결과 캐싱

OpenAI 모델 (75% 할인):
- 시스템 프롬프트 캐싱
- Few-shot 예제 캐싱
- 중간 결과 캐싱
```

### 2. **배치 처리 최대화**
```
GPT-5 배치 API (50% 추가 할인):
- 유사도 계산 작업 (16,290개 쌍)
- 기본 관계 분류 작업
- 가중치 계산 작업

예상 절감 효과: 75% 비용 절감
```

### 3. **총 예상 비용**
| 단계 | 모델 | 기본 비용 | 최적화 후 |
|------|------|-----------|-----------|
| Phase 1 | Gemini 2.5 Pro | $25 | $15 |
| Phase 2 | GPT-5 (배치) | $200 | $50 |
| Phase 3 | Claude Sonnet 4 | $100 | $20 |
| Phase 4 | Claude Opus 4.1 | $150 | $50 |
| **총계** | | **$475** | **$135** |

---

## 🛠️ 기술 구현 세부사항

### 1. **데이터 파이프라인**
```python
# 1단계: PostgreSQL 데이터 추출
def extract_curriculum_data():
    query = """
    SELECT s.standard_code, s.standard_content,
           l.level, l.level_content,
           d.domain_name, g.grade_level
    FROM achievement_standards s
    JOIN achievement_levels l ON s.standard_id = l.standard_id
    JOIN domains d ON s.domain_id = d.domain_id
    JOIN grade_levels g ON s.level_id = g.level_id
    """
    return pd.read_sql(query, conn)

# 2단계: AI 모델별 프롬프트 포맷팅
def format_for_model(data, model_type):
    formatters = {
        'gemini': format_for_gemini,
        'gpt': format_for_gpt, 
        'claude': format_for_claude
    }
    return formatters[model_type](data)

# 3단계: 병렬 API 호출
async def process_with_model(data, model_config):
    semaphore = asyncio.Semaphore(model_config.max_concurrent)
    tasks = [process_single_item(item, semaphore) 
             for item in data]
    return await asyncio.gather(*tasks)
```

### 2. **그래프 구축**
```python
# Neo4j 그래프 생성
def create_knowledge_graph(nodes, edges):
    with driver.session() as session:
        # 노드 생성
        for node in nodes:
            session.run("""
                CREATE (n:AchievementStandard {
                    code: $code,
                    content: $content,
                    difficulty: $difficulty,
                    cognitive_level: $cognitive_level
                })
            """, **node)
        
        # 엣지 생성
        for edge in edges:
            session.run("""
                MATCH (a {code: $source}), (b {code: $target})
                CREATE (a)-[r:RELATION {
                    type: $edge_type,
                    weight: $weight,
                    reasoning: $reasoning
                }]->(b)
            """, **edge)
```

### 3. **품질 보증 시스템**
```python
def validate_graph_quality(graph):
    checks = {
        'cycle_detection': detect_cycles(graph),
        'orphan_nodes': find_orphan_nodes(graph),
        'weight_consistency': check_weight_bounds(graph),
        'coverage_completeness': verify_full_coverage(graph)
    }
    
    for check, result in checks.items():
        if not result.passed:
            log_quality_issue(check, result.details)
            
    return all(check.passed for check in checks.values())
```

---

## 📊 모니터링 및 대시보드

### 1. **실시간 모니터링**
```yaml
대시보드 구성:
  비용 추적:
    - 모델별 누적 비용
    - 일일 API 호출 수
    - 캐싱 절감 효과
    
  처리 진행률:
    - 단계별 완료율
    - 예상 완료 시간
    - 병목 지점 식별
    
  품질 지표:
    - 검증 통과율
    - 전문가 일치도
    - 오류 발생률
```

### 2. **알림 시스템**
```python
alert_conditions = {
    'cost_threshold': {'limit': 200, 'current': 0},
    'error_rate': {'limit': 0.05, 'current': 0}, 
    'quality_score': {'min': 0.85, 'current': 1.0},
    'processing_delay': {'max_hours': 24, 'current': 0}
}
```

---

## 🎯 예상 산출물

### 1. **지식 그래프 구성 요소**
- **노드**: 1,024개 (성취기준 181개 + 성취수준 843개)
- **엣지**: 2,500-4,000개 (관계 유형별 분포)
- **커뮤니티**: 80개 (3레벨 계층 구조)
- **엣지 타입**: 12종 (구조적 4 + 학습순서 4 + 의미적 4)

### 2. **품질 지표 목표**
- **커버리지**: 100% (모든 성취기준 연결)
- **정확도**: 90% 이상 (전문가 검증 기준)
- **일관성**: 순환 참조 0건
- **완전성**: 고아 노드 0개

### 3. **파일 구조**
```
/knowledge_graph_output/
├── nodes/
│   ├── achievement_standards.json
│   ├── achievement_levels.json
│   └── node_attributes.json
├── edges/
│   ├── prerequisite_relations.json
│   ├── similarity_relations.json
│   └── cross_domain_relations.json
├── communities/
│   ├── level_0_clusters.json
│   ├── level_1_clusters.json
│   └── level_2_clusters.json
├── validation/
│   ├── quality_report.json
│   ├── expert_review.json
│   └── consistency_check.json
└── metadata/
    ├── construction_log.json
    ├── cost_summary.json
    └── model_performance.json
```

---

## 🚨 위험 관리 계획

### 1. **기술적 위험**
| 위험 요소 | 발생 확률 | 영향도 | 대응 방안 |
|-----------|-----------|--------|-----------|
| API 장애 | 중간 | 높음 | 다중 모델 백업, 재시도 로직 |
| 비용 초과 | 낮음 | 중간 | 실시간 모니터링, 비상 중단 |
| 품질 저하 | 낮음 | 높음 | 단계별 검증, 전문가 리뷰 |

### 2. **비상 계획**
```python
contingency_plans = {
    'api_failure': {
        'primary': 'Switch to backup model',
        'secondary': 'Use cached results',
        'last_resort': 'Manual intervention'
    },
    'cost_overrun': {
        'threshold_50%': 'Optimize prompts',
        'threshold_75%': 'Reduce scope', 
        'threshold_90%': 'Emergency stop'
    },
    'quality_issues': {
        'score_below_80%': 'Additional validation',
        'score_below_70%': 'Expert review',
        'score_below_60%': 'Process revision'
    }
}
```

---

## 📅 구현 타임라인

### Week 1: 기반 구조 설계
- Day 1-2: Gemini 2.5 Pro 전체 구조 분석
- Day 3-4: 노드 및 속성 정의 완료
- Day 5-7: 초기 관계 구조 설계

### Week 2-3: 관계 추출 및 분류  
- Day 8-10: GPT-5 배치 처리 유사도 계산
- Day 11-14: Claude Sonnet 4 관계 세분화
- Day 15-21: 가중치 계산 및 조정

### Week 4: 검증 및 최적화
- Day 22-24: Claude Opus 4.1 전체 검증
- Day 25-26: 품질 개선 및 수정
- Day 27-28: 최종 산출물 정리

### Week 5: 문서화 및 배포
- Day 29-30: 구축 보고서 작성
- Day 31-32: Neo4j 데이터베이스 구축
- Day 33-35: 시스템 통합 및 테스트

---

## 🎉 성공 요인

### 1. **모델 특성 최적 활용**
- 각 AI 모델의 강점에 맞는 작업 배분
- 비용 효율성과 품질의 균형점 추구
- 최신 기능(캐싱, 배치) 적극 활용

### 2. **품질 보증 체계**
- 다단계 검증 프로세스
- 전문가 검토와 AI 분석 결합
- 지속적 모니터링과 개선

### 3. **실용성 중심 접근**
- 교육 현장의 실제 니즈 반영  
- 단계적 구축으로 위험 최소화
- 확장 가능한 구조 설계

이 방안을 통해 **2025년 최신 AI 기술**을 활용하여 **고품질의 지식 그래프**를 **합리적 비용**으로 구축할 수 있습니다.