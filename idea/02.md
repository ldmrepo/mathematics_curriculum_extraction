## 🤖 LLM 기반 수학 문항 자동분류 시스템 - 고급 모델 활용 전략

### 1. 상용 LLM API 활용 전략

#### 1.1 모델별 특성 및 활용 방안

##### **OpenAI GPT-4/GPT-4-Turbo**
```
강점:
- 수학적 추론 능력 우수
- Function Calling으로 구조화된 출력
- Vision API로 도형/그래프 문제 처리
- Assistants API로 지속적 컨텍스트 관리

활용 방안:
- 복잡한 문항 의미 분석 (Chain of Thought)
- 수식/도형 포함 문항 처리 (GPT-4V)
- 문항 생성 및 변형 (Fine-tuning)
- 채점 기준 및 해설 자동 생성
```

##### **Anthropic Claude 3 (Opus/Sonnet/Haiku)**
```
강점:
- 긴 컨텍스트 처리 (200K tokens)
- 교육적 설명 생성 능력
- 안전성과 정확성 중시
- Constitutional AI로 편향 최소화

활용 방안:
- 전체 교육과정 문서 임베딩
- 상세한 교육적 피드백 생성
- 복수 문항 간 관계 분석
- 교육 철학 기반 문항 평가
```

##### **Google Gemini Pro/Ultra**
```
강점:
- 멀티모달 네이티브 지원
- 수학/과학 도메인 특화
- 실시간 추론 속도
- Vertex AI 통합 MLOps

활용 방안:
- 복합 미디어 문항 처리
- 실시간 문항 분류 서비스
- 대규모 배치 처리
- AutoML과 연계한 커스텀 모델
```

#### 1.2 하이브리드 오케스트레이션
```yaml
문항 분류 파이프라인:
  1차 스크리닝:
    model: Claude Haiku / GPT-3.5
    task: 빠른 영역/학년 분류
    cost: Low
    
  2차 정밀 분석:
    model: GPT-4 / Claude Opus
    task: 성취기준 매칭, 난이도 판정
    cost: Medium
    
  3차 검증/보강:
    model: Gemini Pro
    task: 시각 자료 분석, 교차 검증
    cost: Medium
    
  특수 케이스:
    model: 도메인 특화 Fine-tuned 모델
    task: 엣지 케이스, 신유형 문항
```

### 2. Fine-tuning 전략

#### 2.1 OpenAI Fine-tuning 접근법

##### **데이터 준비 전략**
```json
{
  "messages": [
    {
      "role": "system",
      "content": "당신은 한국 수학 교육과정 전문가입니다. 주어진 문항을 2022 개정 교육과정 성취기준에 따라 분류하세요."
    },
    {
      "role": "user",
      "content": "문항: 두 자리 수 24와 35를 더하시오."
    },
    {
      "role": "assistant",
      "content": {
        "classification": {
          "grade_level": "초1-2",
          "domain": "수와 연산",
          "achievement_standard": "[2수01-04]",
          "achievement_level": "B",
          "concepts": ["덧셈", "두 자리 수"],
          "difficulty": 2,
          "cognitive_level": "이해"
        }
      }
    }
  ]
}
```

##### **Fine-tuning 구성**
```python
Fine-tuning 설정:
- Base Model: gpt-3.5-turbo-1106 or gpt-4-1106-preview
- Training Examples: 10,000+ 라벨링된 문항
- Validation Set: 2,000 문항
- Hyperparameters:
  - n_epochs: 3-5
  - batch_size: 8-16
  - learning_rate_multiplier: 0.5-2.0
  - temperature: 0.3 (일관성 우선)
```

#### 2.2 오픈소스 LLM Fine-tuning

##### **모델 선택 기준**
```
한국어 특화 모델:
- Polyglot-Ko (1.3B - 12.8B)
- KoAlpaca (7B, 13B)
- KULLM (7B, 13B)
- HyperCLOVA X (비공개, API만)

수학 특화 모델:
- WizardMath (7B, 13B, 70B)
- MetaMath (7B, 13B, 70B)
- MAmmoTH (7B, 13B)
- Llemma (7B, 34B)

멀티링구얼 모델:
- Llama 2/3 (7B, 13B, 70B)
- Mistral/Mixtral (7B, 8x7B)
- Qwen (7B, 14B, 72B)
- Yi (6B, 34B)
```

##### **Fine-tuning 기법**
```yaml
LoRA (Low-Rank Adaptation):
  장점: 메모리 효율적, 빠른 학습
  설정:
    r: 8-16
    lora_alpha: 16-32
    target_modules: ["q_proj", "v_proj"]
    
QLoRA (Quantized LoRA):
  장점: 4-bit 양자화로 메모리 절약
  설정:
    bnb_4bit_compute_dtype: float16
    bnb_4bit_quant_type: "nf4"
    
Full Fine-tuning:
  장점: 최고 성능
  요구사항: 높은 GPU 메모리 (A100 80GB+)
  
Instruction Tuning:
  형식: Alpaca, ShareGPT, OpenAI Chat
  데이터: 한국 수학 교육과정 특화
```

### 3. RAG (Retrieval Augmented Generation) 구현

#### 3.1 지식 베이스 구축
```
벡터 데이터베이스 구성:
├── 성취기준 임베딩 (181개)
│   ├── 성취기준 코드
│   ├── 성취기준 내용
│   └── 관련 개념 태그
│
├── 성취수준 임베딩 (843개)
│   ├── 수준별 설명
│   └── 평가 기준
│
├── 예시 문항 임베딩 (10,000+)
│   ├── 문항 텍스트
│   ├── 정답 분류
│   └── 메타데이터
│
└── 교육과정 해설 임베딩
    ├── 영역별 설명
    ├── 학년별 특성
    └── 교수학습 방법
```

#### 3.2 RAG 파이프라인
```python
RAG 워크플로우:
1. Query Embedding: 입력 문항 벡터화
2. Similarity Search: 유사 성취기준/문항 검색
3. Context Construction: 관련 정보 조합
4. Prompt Engineering: 구조화된 프롬프트 생성
5. LLM Generation: 컨텍스트 기반 분류
6. Post-processing: 결과 검증 및 정제

벡터 DB 옵션:
- Pinecone: 관리형, 확장성 우수
- Weaviate: 하이브리드 검색 지원
- Chroma: 경량, 로컬 개발 적합
- Qdrant: 온프레미스, 고성능
```

### 4. 프롬프트 엔지니어링 전략

#### 4.1 Few-shot Learning 템플릿
```python
system_prompt = """
당신은 한국 2022 개정 수학과 교육과정 분류 전문가입니다.
다음 분류 체계를 정확히 따르세요:
- 학년군: [초1-2, 초3-4, 초5-6, 중1-3]
- 영역: [수와 연산, 변화와 관계, 도형과 측정, 자료와 가능성]
- 성취기준: [학년코드수영역코드-순번] 형식
- 성취수준: 초등(A,B,C), 중등(A,B,C,D,E)
"""

few_shot_examples = [
    {
        "input": "삼각형의 내각의 합을 구하시오.",
        "output": {
            "grade": "초3-4",
            "domain": "도형과 측정",
            "standard": "[4수03-03]",
            "level": "B",
            "reasoning": "삼각형의 기본 성질을 묻는 문항"
        }
    },
    # ... 더 많은 예시
]
```

#### 4.2 Chain of Thought (CoT) 프롬프트
```
문항 분석 단계:
1. 핵심 수학 개념 추출
2. 필요한 사전 지식 확인
3. 문제 해결 과정 복잡도 평가
4. 유사 성취기준 후보 나열
5. 최종 성취기준 선택 및 근거
6. 성취수준 판정 근거
```

### 5. 모델 앙상블 및 평가

#### 5.1 앙상블 전략
```yaml
Voting Ensemble:
  models:
    - GPT-4 (weight: 0.35)
    - Claude-3 (weight: 0.35)
    - Fine-tuned Llama (weight: 0.20)
    - Rule-based (weight: 0.10)
  
  aggregation: weighted_majority_vote
  confidence_threshold: 0.75
  
Stacking Ensemble:
  level_1:
    - OpenAI Embedding + Classifier
    - Claude RAG Pipeline
    - Fine-tuned Model
  level_2:
    meta_learner: XGBoost
```

#### 5.2 평가 메트릭
```python
평가 지표:
- Accuracy: 전체 정확도
- F1-Score: 클래스별 균형 평가
- Cohen's Kappa: 평가자 간 일치도
- Mean Reciprocal Rank: 순위 예측 정확도
- Confidence Calibration: 신뢰도 보정

A/B 테스트:
- Champion Model: 현재 프로덕션 모델
- Challenger Model: 새로운 모델/버전
- Test Duration: 2주
- Success Metrics: +5% accuracy improvement
```

### 6. 비용 최적화 전략

#### 6.1 계층적 라우팅
```
트래픽 라우팅:
┌─────────────┐
│  입력 문항   │
└──────┬──────┘
       ↓
┌──────────────┐
│ 난이도 판별기 │ → Simple: GPT-3.5/Claude Haiku (80%)
└──────┬───────┘
       ↓
    Complex: GPT-4/Claude Opus (20%)
       ↓
┌──────────────┐
│  Edge Cases  │ → Fine-tuned Model (5%)
└──────────────┘
```

#### 6.2 캐싱 전략
```python
캐싱 레벨:
1. Exact Match Cache: 동일 문항 즉시 반환
2. Semantic Cache: 유사 문항 결과 참조
3. Partial Cache: 중간 결과 재사용
4. Model Cache: 임베딩 벡터 저장

TTL 설정:
- Hot Cache: 1시간 (자주 조회)
- Warm Cache: 24시간 (일반)
- Cold Cache: 7일 (드물게 조회)
```

### 7. 프로덕션 고려사항

#### 7.1 MLOps 파이프라인
```yaml
CI/CD Pipeline:
  develop:
    - 데이터 검증
    - 모델 학습
    - 단위 테스트
    
  staging:
    - A/B 테스트
    - 성능 벤치마크
    - 부하 테스트
    
  production:
    - Blue-Green 배포
    - 모니터링
    - 롤백 준비
```

#### 7.2 모니터링 및 관찰성
```
모니터링 대시보드:
- API 응답 시간 (P50, P95, P99)
- 모델 정확도 트렌드
- 비용 추적 (모델별, 시간대별)
- 에러율 및 재시도율
- 사용자 피드백 스코어

알림 설정:
- 정확도 하락 > 5%
- 응답 시간 > 2초
- 비용 급증 > 150%
- 에러율 > 1%
```

이러한 고급 모델 활용 전략을 통해 높은 정확도와 효율성을 갖춘 문항 분류 시스템을 구축할 수 있으며, 지속적인 개선과 확장이 가능한 구조를 만들 수 있습니다.