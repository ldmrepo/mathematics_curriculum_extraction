#!/usr/bin/env python3
"""
í•˜ë“œì½”ë”©/ëª©ì—… ë°ì´í„° ì œê±° ìŠ¤í¬ë¦½íŠ¸
ì‹ ë¢°ë„ ë‚®ì€ ë°ì´í„°ë¥¼ ì‹ë³„í•˜ê³  ì œê±°í•©ë‹ˆë‹¤.
"""

import psycopg2
from loguru import logger

class DataCleanup:
    def __init__(self):
        self.conn = psycopg2.connect(
            host="localhost",
            port=5432,
            database="mathematics_curriculum",
            user="postgres",
            password="postgres123"
        )
        self.cursor = self.conn.cursor()
        
    def cleanup_random_contexts(self):
        """ëœë¤ìœ¼ë¡œ ìƒì„±ëœ standard_contexts ì œê±°"""
        logger.info("Cleaning up random context mappings...")
        
        # evidence_textê°€ 'Auto-generated'ì¸ ëª¨ë“  ë ˆì½”ë“œ ì‚­ì œ
        self.cursor.execute("""
            DELETE FROM curriculum.standard_contexts
            WHERE evidence_text = 'Auto-generated context mapping'
        """)
        deleted = self.cursor.rowcount
        self.conn.commit()
        logger.info(f"  Deleted {deleted} random context mappings")
        
    def cleanup_hardcoded_learning_elements(self):
        """í•˜ë“œì½”ë”©ëœ learning_elements ì œê±°"""
        logger.info("Cleaning up hardcoded learning elements...")
        
        # í•˜ë“œì½”ë”©ëœ íŒ¨í„´ì˜ í•™ìŠµ ìš”ì†Œ ì‚­ì œ
        hardcoded_names = [
            'ìˆ˜ì™€ ì—°ì‚°ì˜ ì´í•´%',
            'ê¸°í•˜í•™ì  ì‚¬ê³ %',
            'ì¸¡ì •ê³¼ ë‹¨ìœ„%',
            'ìë£Œì˜ ìˆ˜ì§‘ê³¼ ì •ë¦¬%',
            'í™•ë¥ ê³¼ í†µê³„%'
        ]
        
        for pattern in hardcoded_names:
            self.cursor.execute("""
                DELETE FROM curriculum.learning_elements
                WHERE element_name LIKE %s
            """, (pattern,))
        
        deleted = self.cursor.rowcount
        self.conn.commit()
        logger.info(f"  Deleted {deleted} hardcoded learning elements")
        
    def cleanup_fixed_domain_levels(self):
        """ê³ ì •ê°’ìœ¼ë¡œ ìƒì„±ëœ domain_achievement_levels ì œê±°"""
        logger.info("Cleaning up fixed domain achievement levels...")
        
        # ëª¨ë“  level_codeê°€ 'A'ì¸ ë ˆì½”ë“œ ì‚­ì œ
        self.cursor.execute("""
            DELETE FROM curriculum.domain_achievement_levels
            WHERE level_code = 'A' 
            AND level_description LIKE 'Level%Domain%'
        """)
        deleted = self.cursor.rowcount
        self.conn.commit()
        logger.info(f"  Deleted {deleted} fixed domain levels")
        
    def cleanup_low_confidence_mappings(self):
        """ì‹ ë¢°ë„ ë‚®ì€ ë§¤í•‘ ì œê±°"""
        logger.info("Cleaning up low confidence mappings...")
        
        # standard_termsì—ì„œ confidence < 0.3 ì œê±°
        self.cursor.execute("""
            DELETE FROM curriculum.standard_terms
            WHERE confidence < 0.3
        """)
        terms_deleted = self.cursor.rowcount
        
        # standard_competenciesì—ì„œ confidence < 0.3 ì œê±°
        self.cursor.execute("""
            DELETE FROM curriculum.standard_competencies
            WHERE confidence < 0.3
        """)
        comp_deleted = self.cursor.rowcount
        
        # standard_representationsì—ì„œ ê¸°ë³¸ê°’(0.5) + evidenceê°€ 'Default'ì¸ ê²ƒ ì œê±°
        self.cursor.execute("""
            DELETE FROM curriculum.standard_representations
            WHERE confidence = 0.5 AND evidence_text = 'Default'
        """)
        rep_deleted = self.cursor.rowcount
        
        self.conn.commit()
        logger.info(f"  Deleted {terms_deleted} low confidence term mappings")
        logger.info(f"  Deleted {comp_deleted} low confidence competency mappings")
        logger.info(f"  Deleted {rep_deleted} default representation mappings")
        
    def verify_real_data(self):
        """ì‹¤ì œ ë°ì´í„°ë§Œ ë‚¨ì•˜ëŠ”ì§€ í™•ì¸"""
        logger.info("\nâœ… Verifying remaining data...")
        
        tables = [
            'achievement_standard_relations',
            'standard_terms',
            'standard_competencies',
            'standard_representations',
            'standard_contexts',
            'learning_elements',
            'domain_achievement_levels'
        ]
        
        for table in tables:
            self.cursor.execute(f"SELECT COUNT(*) FROM curriculum.{table}")
            count = self.cursor.fetchone()[0]
            
            # method ì»¬ëŸ¼ì´ ìˆëŠ” í…Œì´ë¸”ì€ methodë³„ë¡œ ì§‘ê³„
            if table in ['standard_terms', 'standard_competencies', 'standard_representations', 'standard_contexts']:
                self.cursor.execute(f"""
                    SELECT method, COUNT(*) 
                    FROM curriculum.{table} 
                    GROUP BY method
                """)
                methods = self.cursor.fetchall()
                method_str = ", ".join([f"{m[0]}:{m[1]}" for m in methods])
                logger.info(f"  {table}: {count} records ({method_str})")
            else:
                logger.info(f"  {table}: {count} records")
                
    def generate_cleanup_report(self):
        """ì œê±° ê²°ê³¼ ë³´ê³ ì„œ"""
        logger.info("\n" + "="*60)
        logger.info("ë°ì´í„° í´ë¦°ì—… ì™„ë£Œ ë³´ê³ ì„œ")
        logger.info("="*60)
        
        # ë‚¨ì€ ë°ì´í„° í’ˆì§ˆ í‰ê°€
        self.cursor.execute("""
            SELECT 
                'standard_contexts' as table_name,
                COUNT(*) as total,
                AVG(confidence) as avg_confidence,
                MIN(confidence) as min_confidence,
                MAX(confidence) as max_confidence
            FROM curriculum.standard_contexts
            WHERE confidence IS NOT NULL
            
            UNION ALL
            
            SELECT 
                'standard_terms' as table_name,
                COUNT(*) as total,
                AVG(confidence) as avg_confidence,
                MIN(confidence) as min_confidence,
                MAX(confidence) as max_confidence
            FROM curriculum.standard_terms
            WHERE confidence IS NOT NULL
            
            UNION ALL
            
            SELECT 
                'standard_competencies' as table_name,
                COUNT(*) as total,
                AVG(confidence) as avg_confidence,
                MIN(confidence) as min_confidence,
                MAX(confidence) as max_confidence
            FROM curriculum.standard_competencies
            WHERE confidence IS NOT NULL
        """)
        
        logger.info("\nğŸ“Š ë‚¨ì€ ë°ì´í„° í’ˆì§ˆ í†µê³„:")
        for row in self.cursor.fetchall():
            if row[1] > 0:  # ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ
                logger.info(f"  {row[0]}:")
                logger.info(f"    - Count: {row[1]}")
                logger.info(f"    - Avg confidence: {row[2]:.3f}")
                logger.info(f"    - Min confidence: {row[3]:.3f}")
                logger.info(f"    - Max confidence: {row[4]:.3f}")
                
    def run_cleanup(self):
        """ì „ì²´ í´ë¦°ì—… ì‹¤í–‰"""
        try:
            logger.info("Starting data cleanup...")
            
            # 1. ëœë¤ ìƒì„± ë°ì´í„° ì œê±°
            self.cleanup_random_contexts()
            
            # 2. í•˜ë“œì½”ë”©ëœ ë°ì´í„° ì œê±°
            self.cleanup_hardcoded_learning_elements()
            
            # 3. ê³ ì •ê°’ ë°ì´í„° ì œê±°
            self.cleanup_fixed_domain_levels()
            
            # 4. ì €ì‹ ë¢°ë„ ë°ì´í„° ì œê±°
            self.cleanup_low_confidence_mappings()
            
            # 5. ê²€ì¦
            self.verify_real_data()
            
            # 6. ë³´ê³ ì„œ
            self.generate_cleanup_report()
            
            logger.info("\nâœ… Cleanup completed successfully!")
            
        except Exception as e:
            logger.error(f"Cleanup failed: {e}")
            self.conn.rollback()
            raise
        finally:
            self.conn.close()

def main():
    print("\n" + "="*60)
    print("í•˜ë“œì½”ë”©/ëª©ì—… ë°ì´í„° ì œê±°")
    print("="*60)
    print("\në‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:")
    print("1. ëœë¤ ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸ ë§¤í•‘ ì œê±°")
    print("2. í•˜ë“œì½”ë”©ëœ í•™ìŠµ ìš”ì†Œ ì œê±°")
    print("3. ê³ ì •ê°’ ë„ë©”ì¸ ë ˆë²¨ ì œê±°")
    print("4. ì‹ ë¢°ë„ < 0.3ì¸ ë§¤í•‘ ì œê±°")
    print("5. ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±ëœ í‘œí˜„ ë°©ë²• ì œê±°")
    
    response = input("\nâš ï¸  ê²½ê³ : ë°ì´í„°ê°€ ì‚­ì œë©ë‹ˆë‹¤. ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    
    if response.lower() == 'y':
        cleanup = DataCleanup()
        cleanup.run_cleanup()
    else:
        print("ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()